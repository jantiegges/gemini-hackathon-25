/**
 * Video Learning Card
 *
 * Uses Google Cloud Vertex AI Veo 3.1 to generate educational videos on-demand.
 * The video demonstrates concepts visually to enhance learning.
 */

import type {
	CardTypeDefinition,
	GeneratedCard,
	GeneratorContext,
} from "../types";

/**
 * Content structure for the Video Learning Card
 */
export interface VideoLearningCardContent {
	/** Topic of the video */
	topic: string;
	/** Path to the generated video in Supabase Storage */
	videoPath: string;
	/** Description/alt text for the video */
	description: string;
	/** The prompt used to generate the video (for debugging/reference) */
	promptContext: string;
	/** Duration of the video in seconds */
	duration: number;
	/** Optional caption shown below the video */
	caption?: string;
	/** Thumbnail image path (first frame) */
	thumbnailPath?: string;
}

/**
 * Veo 3.1 API constraints
 */
const VEO_CONSTRAINTS = {
	aspectRatio: "16:9",
	resolution: "1080p",
	maxDurationSeconds: 8,
} as const;

/**
 * Build an optimized video generation prompt following the formula:
 * [Cinematography] + [Subject] + [Action] + [Context] + [Style & Ambiance]
 */
function buildVideoPrompt(topic: string, focus: string): string {
	return `Cinematic medium shot demonstrating the concept of ${topic}. ${focus}. 
The scene shows clear visual representation with natural studio-quality lighting. 
Slow smooth pan, stable shot. Educational context with professional presentation.
High resolution, photorealistic, 4K, highly detailed. 
Ambient sound only.`;
}

/**
 * Negative prompt to avoid common issues
 */
const NEGATIVE_PROMPT =
	"text, subtitles, watermark, distorted, cartoon, animation, cgi, morphing, blurry, low quality, abstract, logos, graphics overlay";

export const videoLearningCard: CardTypeDefinition = {
	type: "video_learning",
	name: "Video Learning",
	description:
		"An AI-generated educational video that visually demonstrates a concept. Uses Veo 3.1 to create short, focused video clips that enhance understanding through visual learning.",
	bestUsedFor:
		"Demonstrating processes, visualizing abstract concepts, showing real-world applications, or bringing scientific phenomena to life. Great for visual learners and complex spatial concepts.",
	exampleOutput: {
		topic: "Cellular Mitosis",
		videoPath: "cards/lesson-123/video-abc.mp4",
		description:
			"A video showing the stages of cell division with clear visual progression",
		promptContext:
			"Cinematic medium shot demonstrating the concept of cellular mitosis...",
		duration: 8,
		caption: "Watch how a cell divides into two identical daughter cells",
	},

	generate: async (context: GeneratorContext): Promise<GeneratedCard> => {
		// Step 1: Generate metadata and the video prompt using Gemini
		const metadataResult = await context.genAI.models.generateContent({
			model: "gemini-2.5-flash",
			contents: [
				{
					role: "user",
					parts: [
						{
							text: `You are creating an educational video for a learning app.

Lesson: ${context.lessonTitle}
${context.lessonDescription ? `Description: ${context.lessonDescription}` : ""}

Content to visualize:
${context.lessonContent.slice(0, 6000)}

Your task: Create a video concept that ${context.focus}

The video will be generated by an AI video model (Veo 3.1). Provide:
1. A clear topic title
2. A specific description of what should be shown in the video
3. A detailed action description for the video (what movement/changes happen)
4. A short educational caption

The video prompt should describe:
- Real-world, photorealistic visuals (NOT animation or CGI)
- Clear, educational demonstration of the concept
- Smooth, cinematic camera work
- Professional, well-lit scenes
- NO text overlays or graphics (we add those separately)

Return ONLY a JSON object:
{
  "topic": "The Water Cycle",
  "visualDescription": "A scenic view of a lake with water evaporating, rising as mist, forming clouds in the sky, and finally falling as rain",
  "actionDescription": "Show water evaporating from a lake surface, mist rising upward, clouds forming, and rain beginning to fall",
  "caption": "Watch the continuous journey of water through evaporation, condensation, and precipitation"
}

No markdown code blocks, just the raw JSON.`,
						},
					],
				},
			],
		});

		const metadataText = metadataResult.text || "{}";
		const cleanedMetadata = metadataText
			.replace(/```json\n?/g, "")
			.replace(/```\n?/g, "")
			.trim();

		let metadata: {
			topic: string;
			visualDescription: string;
			actionDescription: string;
			caption?: string;
		};

		try {
			metadata = JSON.parse(cleanedMetadata);
		} catch {
			metadata = {
				topic: context.lessonTitle,
				visualDescription: `A clear visual demonstration of ${context.focus}`,
				actionDescription: `Shows ${context.focus} with smooth camera movement`,
				caption: `Understanding ${context.focus}`,
			};
		}

		// Step 2: Build the full video generation prompt
		const videoPrompt = buildVideoPrompt(
			metadata.topic,
			metadata.actionDescription,
		);

		// Step 3: Generate the video using Vertex AI Veo 3.1
		try {
			const videoResult = await generateVideoWithVeo(
				videoPrompt,
				context.lessonId,
			);

			if (!videoResult.success || !videoResult.videoData) {
				throw new Error(videoResult.error || "Video generation failed");
			}

			// Step 4: Upload video to Supabase Storage
			const fileName = `video-${crypto.randomUUID()}.mp4`;
			const filePath = `cards/${context.lessonId}/${fileName}`;

			const { error: uploadError } = await context.supabase.storage
				.from("documents")
				.upload(filePath, videoResult.videoData, {
					contentType: "video/mp4",
					cacheControl: "3600",
				});

			if (uploadError) {
				throw new Error(`Upload failed: ${uploadError.message}`);
			}

			return {
				type: "video_learning",
				content: {
					topic: metadata.topic,
					videoPath: filePath,
					description: metadata.visualDescription,
					promptContext: videoPrompt,
					duration: VEO_CONSTRAINTS.maxDurationSeconds,
					caption: metadata.caption,
				} as VideoLearningCardContent,
			};
		} catch (videoError) {
			console.error("[VideoLearning] Video generation failed:", videoError);

			// Fallback: return a text-based card with the concept explanation
			return {
				type: "text",
				content: {
					title: `ðŸ“¹ ${metadata.topic}`,
					body: `**Visual Concept: ${metadata.topic}**\n\n${metadata.visualDescription}\n\n_${metadata.caption || ""}_\n\n> Note: Video generation is currently unavailable. Please review the concept description above.`,
				},
			};
		}
	},
};

/**
 * Result from Veo video generation
 */
interface VeoGenerationResult {
	success: boolean;
	videoData?: Uint8Array;
	error?: string;
}

/**
 * Generate video using Google Cloud Vertex AI Veo 3.1
 *
 * This function handles the Veo API call with proper error handling
 * for quotas, timeouts, and other potential issues.
 */
async function generateVideoWithVeo(
	prompt: string,
	lessonId: string,
): Promise<VeoGenerationResult> {
	const projectId = process.env.GOOGLE_CLOUD_PROJECT_ID;
	const location = process.env.GOOGLE_CLOUD_LOCATION || "europe-west1";

	if (!projectId) {
		console.warn(
			"[Veo] GOOGLE_CLOUD_PROJECT_ID not set, video generation disabled",
		);
		return {
			success: false,
			error:
				"Video generation not configured. Missing GOOGLE_CLOUD_PROJECT_ID.",
		};
	}

	try {
		// Import the Vertex AI SDK dynamically
		const { VertexAI } = await import("@google-cloud/vertexai");

		const vertexAI = new VertexAI({
			project: projectId,
			location: location,
		});

		// Get the Veo generative model
		const generativeModel = vertexAI.preview.getGenerativeModel({
			model: "veo-3.1-generate-001",
		});

		console.log(`[Veo] Generating video for lesson ${lessonId}...`);
		console.log(`[Veo] Prompt: ${prompt.slice(0, 200)}...`);

		// Generate the video
		const response = await generativeModel.generateContent({
			contents: [
				{
					role: "user",
					parts: [
						{
							text: prompt,
						},
					],
				},
			],
			generationConfig: {
				// Veo-specific configuration
				aspectRatio: VEO_CONSTRAINTS.aspectRatio,
				durationSeconds: VEO_CONSTRAINTS.maxDurationSeconds,
				negativePrompt: NEGATIVE_PROMPT,
			},
		});

		// Extract video data from response
		const result = await response.response;

		if (result.candidates?.[0]?.content?.parts) {
			for (const part of result.candidates[0].content.parts) {
				// Check for video data in the response
				if (
					(part as any).videoMetadata?.mimeType?.startsWith("video/") ||
					part.inlineData?.mimeType?.startsWith("video/")
				) {
					const videoBase64 = part.inlineData?.data;
					if (videoBase64) {
						const binaryString = atob(videoBase64);
						const bytes = new Uint8Array(binaryString.length);
						for (let i = 0; i < binaryString.length; i++) {
							bytes[i] = binaryString.charCodeAt(i);
						}
						console.log(
							`[Veo] Video generated successfully: ${bytes.length} bytes`,
						);
						return { success: true, videoData: bytes };
					}
				}
			}
		}

		// Check for operation-based response (async generation)
		// @ts-expect-error - Long-running operation response
		if (result.name && result.name.includes("operations")) {
			// This is a long-running operation - we need to poll for completion
			// For now, return error as this requires additional handling
			return {
				success: false,
				error:
					"Video generation is processing. Long-running operations not yet supported.",
			};
		}

		return {
			success: false,
			error: "No video data in response",
		};
	} catch (error) {
		const errorMessage =
			error instanceof Error ? error.message : "Unknown error";

		// Handle specific error cases
		if (errorMessage.includes("quota")) {
			console.error("[Veo] Quota exceeded:", errorMessage);
			return {
				success: false,
				error: "Video generation quota exceeded. Please try again later.",
			};
		}

		if (errorMessage.includes("timeout") || errorMessage.includes("DEADLINE")) {
			console.error("[Veo] Request timeout:", errorMessage);
			return {
				success: false,
				error: "Video generation timed out. Please try again.",
			};
		}

		if (
			errorMessage.includes("PERMISSION_DENIED") ||
			errorMessage.includes("403")
		) {
			console.error("[Veo] Permission denied:", errorMessage);
			return {
				success: false,
				error: "Video generation not authorized. Check API credentials.",
			};
		}

		console.error("[Veo] Generation error:", errorMessage);
		return {
			success: false,
			error: `Video generation failed: ${errorMessage}`,
		};
	}
}
