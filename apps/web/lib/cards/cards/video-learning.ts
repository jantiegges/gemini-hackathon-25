/**
 * Video Learning Card
 *
 * Uses Google GenAI SDK (Veo) to generate educational videos on-demand.
 * The video demonstrates concepts visually to enhance learning.
 */

import { GoogleGenAI } from "@google/genai";
import type {
	CardTypeDefinition,
	GeneratedCard,
	GeneratorContext,
} from "../types";

/**
 * Content structure for the Video Learning Card
 */
export interface VideoLearningCardContent {
	/** Topic of the video */
	topic: string;
	/** Path to the generated video in Supabase Storage */
	videoPath: string;
	/** Description/alt text for the video */
	description: string;
	/** The prompt used to generate the video (for debugging/reference) */
	promptContext: string;
	/** Duration of the video in seconds */
	duration: number;
	/** Optional caption shown below the video */
	caption?: string;
	/** Thumbnail image path (first frame) */
	thumbnailPath?: string;
}

/**
 * Veo API constraints
 */
const VEO_CONSTRAINTS = {
	aspectRatio: "16:9",
	resolution: "1080p",
	// Veo typically supports 8s or longer depending on configuration
	durationSeconds: 8,
} as const;

/**
 * Build an optimized video generation prompt following the formula:
 * [Cinematography] + [Subject] + [Action] + [Context] + [Style & Ambiance]
 */
function buildVideoPrompt(topic: string, focus: string): string {
	return `Cinematic medium shot demonstrating the concept of ${topic}. ${focus}. 
The scene shows clear visual representation with natural studio-quality lighting. 
Slow smooth pan, stable shot. Educational context with professional presentation.
High resolution, photorealistic, 4K, highly detailed. 
Ambient sound only.`;
}

/**
 * Negative prompt to avoid common issues
 * Note: Not all SDK versions support negative prompt directly in config,
 * but we'll keep it for when it's supported or if we append to prompt.
 */
// const NEGATIVE_PROMPT = "text, subtitles, watermark, distorted, cartoon, animation, cgi, morphing, blurry, low quality, abstract, logos, graphics overlay";

export const videoLearningCard: CardTypeDefinition = {
	type: "video_learning",
	name: "Video Learning",
	description:
		"An AI-generated educational video that visually demonstrates a concept. Uses Veo to create short, focused video clips that enhance understanding through visual learning.",
	bestUsedFor:
		"Demonstrating processes, visualizing abstract concepts, showing real-world applications, or bringing scientific phenomena to life. Great for visual learners and complex spatial concepts.",
	exampleOutput: {
		topic: "Cellular Mitosis",
		videoPath: "cards/lesson-123/video-abc.mp4",
		description:
			"A video showing the stages of cell division with clear visual progression",
		promptContext:
			"Cinematic medium shot demonstrating the concept of cellular mitosis...",
		duration: 8,
		caption: "Watch how a cell divides into two identical daughter cells",
	},

	generate: async (context: GeneratorContext): Promise<GeneratedCard> => {
		// Step 1: Generate metadata and the video prompt using Gemini (Text)
		const metadataResult = await context.genAI.models.generateContent({
			model: "gemini-2.5-flash",
			contents: [
				{
					role: "user",
					parts: [
						{
							text: `You are creating an educational video for a learning app.

Lesson: ${context.lessonTitle}
${context.lessonDescription ? `Description: ${context.lessonDescription}` : ""}

Content to visualize:
${context.lessonContent.slice(0, 6000)}

Your task: Create a video concept that ${context.focus}

The video will be generated by an AI video model (Veo). Provide:
1. A clear topic title
2. A specific description of what should be shown in the video
3. A detailed action description for the video (what movement/changes happen)
4. A short educational caption

The video prompt should describe:
- Real-world, photorealistic visuals (NOT animation or CGI)
- Clear, educational demonstration of the concept
- Smooth, cinematic camera work
- Professional, well-lit scenes
- NO text overlays or graphics (we add those separately)

Return ONLY a JSON object:
{
  "topic": "The Water Cycle",
  "visualDescription": "A scenic view of a lake with water evaporating, rising as mist, forming clouds in the sky, and finally falling as rain",
  "actionDescription": "Show water evaporating from a lake surface, mist rising upward, clouds forming, and rain beginning to fall",
  "caption": "Watch the continuous journey of water through evaporation, condensation, and precipitation"
}

No markdown code blocks, just the raw JSON.`,
						},
					],
				},
			],
		});

		const metadataText = metadataResult.text || "{}";
		const cleanedMetadata = metadataText
			.replace(/```json\n?/g, "")
			.replace(/```\n?/g, "")
			.trim();

		let metadata: {
			topic: string;
			visualDescription: string;
			actionDescription: string;
			caption?: string;
		};

		try {
			metadata = JSON.parse(cleanedMetadata);
		} catch {
			metadata = {
				topic: context.lessonTitle,
				visualDescription: `A clear visual demonstration of ${context.focus}`,
				actionDescription: `Shows ${context.focus} with smooth camera movement`,
				caption: `Understanding ${context.focus}`,
			};
		}

		// Step 2: Build the full video generation prompt
		const videoPrompt = buildVideoPrompt(
			metadata.topic,
			metadata.actionDescription,
		);

		// Step 3: Generate the video using Google GenAI SDK (Veo)
		try {
			const videoResult = await generateVideoWithGenAI(
				videoPrompt,
				context.lessonId,
			);

			if (!videoResult.success || !videoResult.videoData) {
				throw new Error(videoResult.error || "Video generation failed");
			}

			// Step 4: Upload video to Supabase Storage
			const fileName = `video-${crypto.randomUUID()}.mp4`;
			const filePath = `cards/${context.lessonId}/${fileName}`;

			const { error: uploadError } = await context.supabase.storage
				.from("documents")
				.upload(filePath, videoResult.videoData, {
					contentType: "video/mp4",
					cacheControl: "3600",
				});

			if (uploadError) {
				throw new Error(`Upload failed: ${uploadError.message}`);
			}

			return {
				type: "video_learning",
				content: {
					topic: metadata.topic,
					videoPath: filePath,
					description: metadata.visualDescription,
					promptContext: videoPrompt,
					duration: VEO_CONSTRAINTS.durationSeconds,
					caption: metadata.caption,
				} as VideoLearningCardContent,
			};
		} catch (videoError) {
			console.error("[VideoLearning] Video generation failed:", videoError);

			// Fallback: return a text-based card with the concept explanation
			return {
				type: "text",
				content: {
					title: `ðŸ“¹ ${metadata.topic}`,
					body: `**Visual Concept: ${metadata.topic}**\n\n${metadata.visualDescription}\n\n_${metadata.caption || ""}_\n\n> Note: Video generation is currently unavailable. Please review the concept description above.`,
				},
			};
		}
	},
};

/**
 * Result from Veo video generation
 */
interface VeoGenerationResult {
	success: boolean;
	videoData?: Uint8Array;
	error?: string;
}

/**
 * Generate video using Google GenAI SDK (Veo)
 *
 * Uses the unified GoogleGenAI SDK which simplifies auth and polling.
 */
async function generateVideoWithGenAI(
	prompt: string,
	lessonId: string,
): Promise<VeoGenerationResult> {
	const apiKey = process.env.GEMINI_API_KEY;

	if (!apiKey) {
		console.warn("[Veo] GEMINI_API_KEY not set, video generation disabled");
		return {
			success: false,
			error: "Video generation not configured. Missing GEMINI_API_KEY.",
		};
	}

	try {
		console.log(`[Veo] Generating video for lesson ${lessonId}...`);
		console.log(`[Veo] Prompt: ${prompt.slice(0, 200)}...`);

		// Initialize GoogleGenAI client
		const ai = new GoogleGenAI({ apiKey });

		// Configure parameters
		// Note: Model name might need adjustment based on availability (veo-001, veo-2.0-generate-001)
		// Trying 'veo-2.0-generate-001' as a standard managed model
		const model = "veo-2.0-generate-001";

		const generateVideoPayload: any = {
			model: model,
			prompt: prompt,
			config: {
				// resolution is not supported by current Veo model via this SDK method
				// numberOfVideos: 1, // Defaults to 1
			},
		};

		console.log(
			"Submitting video generation request...",
			JSON.stringify(generateVideoPayload, null, 2),
		);

		// Start generation operation
		let operation = await ai.models.generateVideos(generateVideoPayload);
		console.log("Video generation operation started. Name:", operation.name);

		// Poll for completion
		const maxAttempts = 60; // 10 minutes (10s intervals)
		let attempts = 0;

		while (!operation.done && attempts < maxAttempts) {
			await new Promise((resolve) => setTimeout(resolve, 10000)); // Poll every 10s
			attempts++;
			console.log(`...Generating (attempt ${attempts}/${maxAttempts})...`);

			// Refresh operation status
			operation = await ai.operations.getVideosOperation({
				operation: operation,
			});
		}

		if (!operation.done) {
			return {
				success: false,
				error: "Video generation timed out.",
			};
		}

		// Process result
		if (operation?.response) {
			const videos = operation.response.generatedVideos;

			if (!videos || videos.length === 0) {
				return {
					success: false,
					error: "No videos were generated.",
				};
			}

			const firstVideo = videos[0];
			if (!firstVideo?.video?.uri) {
				return {
					success: false,
					error: "Generated video is missing a URI.",
				};
			}

			const videoUri = firstVideo.video.uri;
			const url = decodeURIComponent(videoUri);
			console.log("Fetching video from:", url);

			// Fetch video content
			// Important: Append API key for access if using AI Studio generated URIs
			const fetchUrl = `${url}${url.includes("?") ? "&" : "?"}key=${apiKey}`;

			const res = await fetch(fetchUrl);

			if (!res.ok) {
				return {
					success: false,
					error: `Failed to fetch video: ${res.status} ${res.statusText}`,
				};
			}

			const videoBuffer = await res.arrayBuffer();
			const bytes = new Uint8Array(videoBuffer);

			console.log(`[Veo] Video generated successfully: ${bytes.length} bytes`);
			return { success: true, videoData: bytes };
		}

		console.error("Operation failed or no response:", operation);
		return {
			success: false,
			error: "Video generation operation failed.",
		};
	} catch (error) {
		const errorMessage =
			error instanceof Error ? error.message : "Unknown error";
		console.error("[Veo] Generation error:", errorMessage);
		return {
			success: false,
			error: `Video generation failed: ${errorMessage}`,
		};
	}
}
